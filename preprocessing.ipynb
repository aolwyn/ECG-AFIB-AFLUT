{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing steps for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries required\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import wfdb\n",
    "import pickle\n",
    "import sys\n",
    "import glob\n",
    "from scipy.signal import butter, lfilter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'G:/Datasets/mit-bih-arrhythmia-database-1.0.0/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for GPU \n",
    "background checks, used for making sure CUDA is setup and linked to pytorch. See below for setup:\n",
    "\n",
    "<a href=\"https://developer.nvidia.com/cuda-downloads?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exe_local\n",
    "\" >download cuda</a>\n",
    "\n",
    "```pip uninstall torch torchvision torchaudio```\n",
    "\n",
    "```pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu118```\n",
    "\n",
    "then to verify it downloaded, run the below in terminal:\n",
    "\n",
    "```python -c \"import torch; print('CUDA available:', torch.cuda.is_available(), 'Number of GPUs:', torch.cuda.device_count(), 'Current device:', torch.cuda.current_device(), 'Device name:', torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else 'No GPU found')\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print('CUDA Device Name:', torch.cuda.get_device_name(0))\n",
    "    print('CUDA Version:', torch.version.cuda)\n",
    "    print('PyTorch Version:', torch.__version__)\n",
    "    \n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0) / 1024**3, 1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0) / 1024**3, 1), 'GB')\n",
    "    \n",
    "    # Total memory info\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory\n",
    "    print('Total Memory:', round(total_memory / 1024**3, 1), 'GB')\n",
    "    \n",
    "    free_memory = total_memory - torch.cuda.memory_reserved(0)\n",
    "    print('Free Memory:', round(free_memory / 1024**3, 1), 'GB')\n",
    "\n",
    "    # tensor check, making sure cuda and torch are setup correctly\n",
    "    x = torch.rand(2, 3)\n",
    "    print('Test Tensor:', x)\n",
    "else:\n",
    "    print('Using the CPU, no GPU found')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset, simple data exploration\n",
    "To load the dataset, we will use The `WFDB` (Waveform Database) library. It is a part of the PhysioNet project and is a software package designed for reading, writing, and processing physiological signals, primarily ECG (electrocardiogram) signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_records(path):\n",
    "    \"\"\" Get paths for ECG records in the specified directory. \"\"\" #each pt has 4 files. .atr, .dat, .hea, .xws\n",
    "    # Pattern to find *.atr files\n",
    "    path_source = f'{path}*.atr'\n",
    "    paths = glob.glob(path_source) \n",
    "\n",
    "    # Remove the extensions and sort\n",
    "    records = sorted(path[:-4] for path in paths)\n",
    "    records = [record for record in records if not record.endswith('\\\\102-0')] # 7/06/2018: File 102.atr has been edited. Annotation number 1991 (0 indexed) has been shifted from sample 590296 to 590262 <-- from physionet, orig. @ 102-0.atr\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_patient_info(record_path):\n",
    "    \"\"\"Show patient metadata for a single record.\"\"\"\n",
    "    try:\n",
    "        record = wfdb.rdsamp(record_path)\n",
    "        # NOTE FROM DATASET WEBSITE / LIBRARY - PT ECG DATA SAMPLES IN RECORD[0], PATIENT DATA IN RECORD[1]\n",
    "\n",
    "        metadata = record[1]\n",
    "        print(metadata)\n",
    "        # print(\"Patient Information:\")\n",
    "        # print(f\"Sampling rate (fs): {metadata['fs']}\")\n",
    "        # print(f\"Total number of samples (sig_len): {metadata['sig_len']}\")\n",
    "        # print(f\"Total number of channels (n_sig): {metadata['n_sig']}\")\n",
    "        # print(f\"Base date: {metadata['base_date']}\")\n",
    "        # print(f\"Base time: {metadata['base_time']}\")\n",
    "        # print(f\"Units: {metadata['units']}\")\n",
    "        # print(f\"Channel names: {metadata['sig_name']}\")\n",
    "        # print(f\"Comments: {metadata['comments']}\")\n",
    "        print(\"\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {record_path}, check file name + path xdd\")\n",
    "    except Exception as e:\n",
    "        print(f\"couldn't load file, error: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify all paths / files, print on separate line.\n",
    "record_paths = get_records(file_path)\n",
    "\n",
    "for record in record_paths:\n",
    "    print(record)\n",
    "\n",
    "# print 1 pt's data\n",
    "record_name = file_path+'100'  #record + path to folder\n",
    "show_patient_info(record_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_record(file_path):\n",
    "    \"\"\"\n",
    "    Load ECG signal and annotations for a given record.\n",
    "\n",
    "    Returns:\n",
    "        signal: 2D array (samples, channels)\n",
    "        annotations: Object containing arrhythmia annotations\n",
    "    \"\"\"\n",
    "    record = wfdb.rdrecord(file_path)\n",
    "    signal = record.p_signal  # 2D array with 2 channels\n",
    "    annotations = wfdb.rdann(file_path, 'atr')\n",
    "    return signal, annotations\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    \"\"\"\n",
    "    Design a bandpass filter to remove noise from the ECG signal.\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "# Apply the bandpass filter to the ECG signal\n",
    "def bandpass_filter(signal, lowcut=0.5, highcut=50.0, fs=360, order=3):\n",
    "    \"\"\"\n",
    "    Apply a bandpass filter to the ECG signal.\n",
    "    \"\"\"\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    return lfilter(b, a, signal)\n",
    "\n",
    "def preprocess_signal(signal):\n",
    "    \"\"\"\n",
    "   normalize the signal, apply the filter\n",
    "    \"\"\"\n",
    "    filtered_signal = bandpass_filter(signal)\n",
    "    normalized_signal = (filtered_signal - np.mean(filtered_signal)) / np.std(filtered_signal)\n",
    "    return normalized_signal\n",
    "\n",
    "def segment_signal(signal, segment_size=900):\n",
    "    \"\"\"\n",
    "    Segment the signal into non-overlapping segments.\n",
    "    \"\"\"\n",
    "    num_segments = len(signal) // segment_size\n",
    "    return np.array([signal[i * segment_size:(i + 1) * segment_size] for i in range(num_segments)])\n",
    "\n",
    "def label_segments(segments, annotations, threshold=5):\n",
    "    \"\"\"\n",
    "    Label each segment based on proximity to arrhythmia annotations.\n",
    "    \"\"\"\n",
    "    labels = np.zeros(len(segments))\n",
    "    for ann in annotations.sample:\n",
    "        segment_idx = ann // len(segments[0])\n",
    "        if segment_idx < len(labels):\n",
    "            labels[segment_idx] = 1  # 1 for irregular\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing All Records and Saving\n",
    "This section processes each record using the defined functions, then saves each patient's processed segments and labels into separate files for efficient loading later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dir = './preprocessed_data'\n",
    "os.makedirs(preprocessed_dir, exist_ok=True)\n",
    "\n",
    "# Specify data directory\n",
    "data_dir = file_path[:-1]\n",
    "record_files = [f[:-4] for f in os.listdir(data_dir) if f.endswith('.dat')]\n",
    "\n",
    "# Process and save each record's data\n",
    "for record_name in record_files:\n",
    "    # Load the ECG signal and annotations\n",
    "    signal, annotations = load_record(os.path.join(data_dir, record_name))\n",
    "    \n",
    "    # Preprocess each channel\n",
    "    processed_ch1 = preprocess_signal(signal[:, 0])\n",
    "    processed_ch2 = preprocess_signal(signal[:, 1])\n",
    "    \n",
    "    # Segment each channel\n",
    "    segments_ch1 = segment_signal(processed_ch1)\n",
    "    segments_ch2 = segment_signal(processed_ch2)\n",
    "    \n",
    "    # Stack channels along the last dimension\n",
    "    segments = np.stack((segments_ch1, segments_ch2), axis=-1)\n",
    "    \n",
    "    # Label the segments\n",
    "    labels = label_segments(segments_ch1, annotations)\n",
    "    \n",
    "    # Save preprocessed segments and labels\n",
    "    np.save(os.path.join(preprocessed_dir, f\"{record_name}_segments.npy\"), segments)\n",
    "    np.save(os.path.join(preprocessed_dir, f\"{record_name}_labels.npy\"), labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
